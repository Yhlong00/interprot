{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import esm\n",
    "from sae_model import SparseAutoencoder\n",
    "from esm_wrapper import ESM2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 1280\n",
    "D_HIDDEN = 4096\n",
    "SEQUENCE = 'MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVVAAIVQDIAYLRSLGYNIVATPRGYVLAGG'\n",
    "device = 'cuda:0'\n",
    "weights_dir = '/global/cfs/cdirs/m4351/ml5045/interp_weights'\n",
    "\n",
    "esm2_weight = os.path.join(weights_dir, 'esm2_t33_650M_UR50D.pt')\n",
    "sae_weight = os.path.join(weights_dir, 'sae_weights.pt')\n",
    "alphabet = esm.data.Alphabet.from_architecture(\"ESM-1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2_model = ESM2Model(num_layers=33, embed_dim=1280, attention_heads=20, \n",
    "                       alphabet=alphabet, token_dropout=False, device='cuda:0')\n",
    "esm2_model.load_esm_ckpt(esm2_weight)\n",
    "esm2_model = esm2_model.to(device)\n",
    "sae_model = SparseAutoencoder(D_MODEL, D_HIDDEN).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = esm2_model.get_layer_activations(SEQUENCE, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts, mu, std = sae_model.encode(embed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts.size(), mu.size(), std.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_latents = sae_model.decode(acts, mu, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = esm2_model.get_sequence(updated_latents.unsqueeze(0), 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.argmax(logits[:,1:-1,4:24], dim=-1)  \n",
    "sequences = [''.join([esm2_model.alphabet.all_toks[i+4] for i in sequence.tolist()]) for sequence in list(tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genie_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
